{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-01T02:46:44.413365Z",
     "iopub.status.busy": "2025-05-01T02:46:44.412879Z",
     "iopub.status.idle": "2025-05-01T02:46:55.840898Z",
     "shell.execute_reply": "2025-05-01T02:46:55.839546Z",
     "shell.execute_reply.started": "2025-05-01T02:46:44.413330Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-datasets bert-score rouge-score langchain-google-genai git+https://github.com/google-research/bleurt.git nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-01T03:05:12.014387Z",
     "iopub.status.busy": "2025-05-01T03:05:12.013931Z",
     "iopub.status.idle": "2025-05-01T03:06:01.460767Z",
     "shell.execute_reply": "2025-05-01T03:06:01.459443Z",
     "shell.execute_reply.started": "2025-05-01T03:05:12.014364Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/bleurt-oss-21/BLEURT-20.zip\n",
    "!unzip BLEURT-20.zip -d bleurt-checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-01T03:06:36.060464Z",
     "iopub.status.busy": "2025-05-01T03:06:36.060066Z",
     "iopub.status.idle": "2025-05-01T03:32:44.194687Z",
     "shell.execute_reply": "2025-05-01T03:32:44.193796Z",
     "shell.execute_reply.started": "2025-05-01T03:06:36.060437Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from bert_score import score as bert_score\n",
    "from rouge_score import rouge_scorer\n",
    "from bleurt import score as bleurt_score\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Download NLTK data for METEOR\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Gemini API key\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Prompt template\n",
    "QNA_PROMPT = \"\"\"\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "def clean_context(context):\n",
    "    return context.strip()\n",
    "\n",
    "class Generator:\n",
    "    def __init__(self, model_name=\"models/gemini-2.0-flash\"):\n",
    "        self.llm = GoogleGenerativeAI(model=model_name, google_api_key=\"AIzaSyAzEuo4oO6OLSglM2VceLIlRX1jMMFQnr0\") #GEMINI_API_KEY)\n",
    "\n",
    "    def generate_answer(self, question, chunks):\n",
    "        try:\n",
    "            context = \"\\n\".join(chunks)\n",
    "            prompt = QNA_PROMPT.format(question=question, context=clean_context(context))\n",
    "            answer = self.llm.invoke(prompt)\n",
    "            logging.info(f\"Generated answer for question: {question}\")\n",
    "            return {\"question\": question, \"answer\": answer.strip(), \"references\": None}\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error generating answer: {e}\")\n",
    "            raise\n",
    "\n",
    "def evaluate_metrics(generated_answers, reference_answers):\n",
    "    generated = [str(ans) for ans in generated_answers]\n",
    "    references = [str(ref) for ref in reference_answers]\n",
    "\n",
    "    # BERTScore\n",
    "    P, R, F1 = bert_score(generated, references, lang=\"en\", verbose=False)\n",
    "    bert_scores = {\n",
    "        \"precision\": np.mean(P.numpy()),\n",
    "        \"recall\": np.mean(R.numpy()),\n",
    "        \"f1\": np.mean(F1.numpy())\n",
    "    }\n",
    "\n",
    "    # ROUGE\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge_scores = {\"rouge1\": 0, \"rouge2\": 0, \"rougeL\": 0}\n",
    "    for gen, ref in zip(generated, references):\n",
    "        scores = scorer.score(ref, gen)\n",
    "        for key in rouge_scores:\n",
    "            rouge_scores[key] += scores[key].fmeasure\n",
    "    rouge_scores = {k: v / len(generated) for k, v in rouge_scores.items()}\n",
    "\n",
    "    # BLUERT\n",
    "    # Specify the path to the BLUERT checkpoint (e.g., BLEURT-20)\n",
    "    bleurt_scorer = bleurt_score.BleurtScorer(\"bleurt-checkpoint/BLEURT-20\")\n",
    "    bleurt_scores = bleurt_scorer.score(references=references, candidates=generated)\n",
    "    avg_bleurt = np.mean(bleurt_scores)\n",
    "\n",
    "    # METEOR\n",
    "    meteor_scores = []\n",
    "    for gen, ref in zip(generated, references):\n",
    "        # Tokenize the sentences for METEOR\n",
    "        gen_tokens = word_tokenize(gen)\n",
    "        ref_tokens = word_tokenize(ref)\n",
    "        score = meteor_score([ref_tokens], gen_tokens)\n",
    "        meteor_scores.append(score)\n",
    "    avg_meteor = np.mean(meteor_scores)\n",
    "\n",
    "    return {\n",
    "        \"bertscore\": bert_scores,\n",
    "        \"rouge\": rouge_scores,\n",
    "        \"bleurt\": avg_bleurt,\n",
    "        \"meteor\": avg_meteor\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    from time import sleep\n",
    "    # Load QuAC validation dataset (100 samples)\n",
    "    dataset = tfds.load(\"quac\", split=\"validation\")\n",
    "    \n",
    "    # Initialize generator\n",
    "    generator = Generator()\n",
    "\n",
    "    generated_answers = []\n",
    "    reference_answers = []\n",
    "    \n",
    "    # Process exactly 100 samples\n",
    "    for example in tqdm(dataset.take(100)):\n",
    "        question = example[\"question\"].numpy().decode(\"utf-8\")\n",
    "        context = example[\"context\"].numpy().decode(\"utf-8\")\n",
    "        answer = example[\"answers\"][\"text\"][0].numpy().decode(\"utf-8\")\n",
    "        \n",
    "        reference_answers.append(answer)\n",
    "        response = generator.generate_answer(question, [context])\n",
    "        generated_answers.append(response[\"answer\"])\n",
    "        sleep(5)\n",
    "    # Evaluate metrics\n",
    "    metrics = evaluate_metrics(generated_answers, reference_answers)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Evaluation Metrics (100 samples):\")\n",
    "    print(f\"BERTScore:\")\n",
    "    print(f\"  Precision: {metrics['bertscore']['precision']:.4f}\")\n",
    "    print(f\"  Recall: {metrics['bertscore']['recall']:.4f}\")\n",
    "    print(f\"  F1: {metrics['bertscore']['f1']:.4f}\")\n",
    "    print(f\"ROUGE:\")\n",
    "    print(f\"  ROUGE-1: {metrics['rouge']['rouge1']:.4f}\")\n",
    "    print(f\"  ROUGE-2: {metrics['rouge']['rouge2']:.4f}\")\n",
    "    print(f\"  ROUGE-L: {metrics['rouge']['rougeL']:.4f}\")\n",
    "    print(f\"BLUERT: {metrics['bleurt']:.4f}\")\n",
    "    print(f\"METEOR: {metrics['meteor']:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
